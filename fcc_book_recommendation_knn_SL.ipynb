{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lohan20s/KNeighbors_Book_Recommendation/blob/main/fcc_book_recommendation_knn_SL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y1onB6kUvo4Z"
      },
      "outputs": [],
      "source": [
        "# import libraries (you may add additional imports but you may not have to)\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.sparse import csr_matrix\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iAQGqqO_vo4d",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# get data files\n",
        "!wget https://cdn.freecodecamp.org/project-data/books/book-crossings.zip\n",
        "\n",
        "!unzip book-crossings.zip\n",
        "\n",
        "books_filename = 'BX-Books.csv'\n",
        "ratings_filename = 'BX-Book-Ratings.csv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NClILWOiEd6Q"
      },
      "outputs": [],
      "source": [
        "# import csv data into dataframes\n",
        "#load books\n",
        "df_books = pd.read_csv(\n",
        "    books_filename,\n",
        "    encoding = \"ISO-8859-1\",\n",
        "    sep=\";\",\n",
        "    header=0,\n",
        "    names=['isbn', 'title', 'author'],\n",
        "    usecols=['isbn', 'title', 'author'],\n",
        "    dtype={'isbn': 'str', 'title': 'str', 'author': 'str'})\n",
        "\n",
        "#remove duplicate rows (same book title but different isbns)\n",
        "df_books.drop_duplicates(subset=['title'],inplace=True)\n",
        "print(df_books.head())\n",
        "\n",
        "#load ratings\n",
        "df_ratings = pd.read_csv(\n",
        "    ratings_filename,\n",
        "    encoding = \"ISO-8859-1\",\n",
        "    sep=\";\",\n",
        "    header=0,\n",
        "    names=['user', 'isbn', 'rating'],\n",
        "    usecols=['user', 'isbn', 'rating'],\n",
        "    dtype={'user': 'int32', 'isbn': 'str', 'rating': 'float32'})\n",
        "print(df_ratings.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xAcXjkCFCh0A"
      },
      "outputs": [],
      "source": [
        "#Graph the dataset, you will notice that most books are not rated frequently (rating = 0)\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.hist(df_ratings[\"rating\"], bins=11, edgecolor=\"black\", alpha=0.7)\n",
        "\n",
        "plt.xlabel(\"Ratings\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.title(\"Distribution of Book Ratings\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#remove outliers:remove rows where ratings are zero as that means the book was not rated by the user\n",
        "#df_ratings=df_ratings[df_ratings[\"rating\"]>0]\n",
        "\n",
        "#find users with less than 200 ratings and books with less than 100 ratings and remove them from the dataset\n",
        "user_counts=df_ratings[\"user\"].value_counts()\n",
        "user_keep=user_counts[user_counts>=200].index\n",
        "book_counts=df_ratings[\"isbn\"].value_counts()\n",
        "book_keep=book_counts[book_counts>=100].index\n",
        "df_ratings_filtered=df_ratings[df_ratings[\"user\"].isin(user_keep)& df_ratings[\"isbn\"].isin(book_keep)].reset_index(drop=True)\n"
      ],
      "metadata": {
        "id": "bGNKHTqRoGq8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#merge df_ratings with df_books\n",
        "df_merged = pd.merge(df_books,df_ratings_filtered,left_on = 'isbn', right_on = 'isbn', how = 'right')\n",
        "\n",
        "#aggregate ratings values across users by making a pivot table and converting to csr matrix\n",
        "df_pivottable=df_merged.pivot_table(index='title', columns='user', values='rating').fillna(0)\n",
        "df_ratings_matrix = csr_matrix(df_pivottable.values)\n"
      ],
      "metadata": {
        "id": "xgSqLksW4Es_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#use NearestNeighbors to develop a model that shows books that are similar to a given book.\n",
        "model= NearestNeighbors(metric='cosine',n_neighbors=6)\n",
        "model.fit(df_ratings_matrix)"
      ],
      "metadata": {
        "id": "mHhf1P53yWen"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f5ZUd-L1SQz7"
      },
      "outputs": [],
      "source": [
        "#Create a function named get_recommends that takes a book title (from the dataset) as an argument\n",
        "#and returns a list of 5 similar books with their distances from the book argument.\n",
        "def get_recommends(book = \"\"):\n",
        "  book_rating=csr_matrix(df_pivottable.loc[book])\n",
        "  distances, indices = model.kneighbors(book_rating)\n",
        "  indices=indices.flatten( )\n",
        "  distances=distances.flatten( )\n",
        "  booklist=[]\n",
        "  for i in range(len(indices)-1,1,-1):\n",
        "    booklist.append([df_pivottable.iloc[indices[i]].name,distances[i]])\n",
        "  final_book_list=[book,booklist]\n",
        "  return(final_book_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jd2SLCh8oxMh"
      },
      "outputs": [],
      "source": [
        "books = get_recommends(\"Where the Heart Is (Oprah's Book Club (Paperback))\")\n",
        "print(books)\n",
        "\n",
        "def test_book_recommendation():\n",
        "  test_pass = True\n",
        "  recommends = get_recommends(\"Where the Heart Is (Oprah's Book Club (Paperback))\")\n",
        "  if recommends[0] != \"Where the Heart Is (Oprah's Book Club (Paperback))\":\n",
        "    test_pass = False\n",
        "  recommended_books = [\"I'll Be Seeing You\", 'The Weight of Water', 'The Surgeon', 'I Know This Much Is True']\n",
        "  recommended_books_dist = [0.8, 0.77, 0.77, 0.77]\n",
        "  for i in range(2):\n",
        "    if recommends[1][i][0] not in recommended_books:\n",
        "      test_pass = False\n",
        "    if abs(recommends[1][i][1] - recommended_books_dist[i]) >= 0.05:\n",
        "      test_pass = False\n",
        "  if test_pass:\n",
        "    print(\"You passed the challenge! ðŸŽ‰ðŸŽ‰ðŸŽ‰ðŸŽ‰ðŸŽ‰\")\n",
        "  else:\n",
        "    print(\"You haven't passed yet. Keep trying!\")\n",
        "\n",
        "test_book_recommendation()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}